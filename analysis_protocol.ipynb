{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5bdfc94",
   "metadata": {},
   "source": [
    "# Alphafold models analysis main program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c317f506",
   "metadata": {},
   "source": [
    "##  Description of the materials and program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd66594",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7624a2",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Arial, sans-serif; line-height: 1.5; text-align: justify;\">\n",
    "   \n",
    "This jupyter notebook is created to perform a analysis of complexes generated by different versions of Alphafold. There are main 4 versions of AlphaFold available:\n",
    "\n",
    "- AlphaFold2-Multimer v1 (v1).\n",
    "\n",
    "- AlphaFold2-Multimer v2 (v2).\n",
    "\n",
    "- AlphaFold2-Multimer v3 (v3).\n",
    "\n",
    "- AF3.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa11ba4",
   "metadata": {},
   "source": [
    "### Description of the files and folders of AlphaFold2-Multimer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e25140c",
   "metadata": {},
   "source": [
    "#### Complex folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caec483",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"font-family: Arial, sans-serif; line-height: 1.5; text-align: justify;\">\n",
    "The folder in which the rest files are stored are named by the complex, composed by the name of the cristal in the PDB bank followed by the chains used to do the complex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2d2f0f",
   "metadata": {},
   "source": [
    "#### PDBS files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d526df74",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Arial, sans-serif; line-height: 1; text-align: justify;\">\n",
    "\n",
    "Indicates the information of the protein structure. The names of the PDBs generated by Aplhafold Multimer are composed by: complex,state,rank,version of Alphafold, model and recycle (except cristals,\"ranked\" pdbs and Seed_0 pdbs).<br><br>\n",
    "\n",
    "- Complex: the name of the complex registered in the PDB bank, it  is composed by letters and numbers.<br><br>\n",
    "- States:\n",
    "  - unrelaxed: are crude structures provided by Alphafold in which it does it iterative proccess .\n",
    "  \n",
    "  - relaxed: The last structure recycled relaxed using AMBER  force field in openMM. <br><br>\n",
    "\n",
    "- Version: indicates which version of AlphaFold .<br><br>\n",
    "\n",
    "\n",
    "- Model:\n",
    "\n",
    "  - Models in Alphafold2: generates five predictions from the same seed, are named as \"model_\" followed by a number.\n",
    "  \n",
    "\n",
    "    - \"ranked_\" folled by a number: indicates in which position in the rank are the relaxed models according to the scores that alphafold assigns. Their name is entirely \"ranked\" it has no more data in it.\n",
    "\n",
    "\n",
    "    - \"pred_\" followed by a number: identifies a model generated by the same seed, but with minor differences.<br><br>\n",
    "    \n",
    "  \n",
    "  - Model in the versions of AM (v1,v2,v3,v3_short): the models are generate models 5 model from differents seeds and then it iterates the resolution of the structure until the tol variable surpass a threshold in which alphafold stop modeling ot reaches the recycle of 20.<br><br>\n",
    "\n",
    "- Recycle: only for non-Alphafold2 predictions (at te moment).\n",
    "  \n",
    "  - \"r_\" followed by number : indicates the recycle of the model.\n",
    "\n",
    "\n",
    "  - \"Seed_0\": is the same from recycle 20 that will be relaxed.<br><br>\n",
    "  \n",
    "- Rank folllowed by a number : it indicates which model of the five generated is best according to the highest score obtained in the last recyle, only in Alphafold2.<br><br>\n",
    "\n",
    "\n",
    "- Examples of names:\n",
    "\n",
    "\n",
    "  - unrelaxed_rank_001_alphafold2_multimer_v2_model_4_seed_000_r9.pdb (standart name in AM versions).\n",
    "\n",
    "\n",
    "  - relaxed_model_4_multimer_v2_pred_1.pdb (standart name in Alphafold2 versions).\n",
    "\n",
    "\n",
    "  - 3BT1.pdb (crystal).\n",
    "\n",
    "\n",
    "  - ranked_0.pdb (relaxed and ranked in Alphafold2).\n",
    "\n",
    "  \n",
    "  - unrelaxed_rank_001_alphafold2_multimer_v3_model_2_seed_000_r0 ( Seed_0 example).\n",
    "\n",
    "   \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0d3f39",
   "metadata": {},
   "source": [
    "#### Log.txt files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429a44d6",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Arial, sans-serif; line-height: 1; text-align: justify;\">\n",
    "   \n",
    "It gathers infromation about the execution of alphafold, the most relevant information is:\n",
    "\n",
    "- Timestamps: The file starts with timestamps indicating when each event occurred. These timestamps are in the format \"YYYY-MM-DD HH:MM:SS,sss\" (Year, Month, Day, Hour, Minute, Second, Milliseconds).\n",
    "\n",
    "- Information about the software: The first few entries provide information about the software version (ColabFold 1.5.2).\n",
    "\n",
    "- Recycle iterations: The log then proceeds to provide information about the iterative process of protein structure prediction. It mentions recycling and various metrics such as \"pLDDT,\" \"pTM,\" \"ipTM,\" and \"tol\" for each recycle step.\n",
    "\n",
    "- Model ranking: The final section ranks the models based on the \"multimer\" metric, and it mentions the relaxation times for each model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc5a48f",
   "metadata": {},
   "source": [
    "### Description of the files and folders of Alphafold 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73abc518",
   "metadata": {},
   "source": [
    "#### JSON\n",
    "\n",
    "Full-data JSON: It gives detailed information about each residue\n",
    "\n",
    "Job_request JSOn: is the job submited to AF3 server. It contains the name of the job (usually the modeled complex), the seed designated (random) and the sequences of the desired molecules. If this job is uploaded to AF3 server y reproduces the same results.\n",
    "\n",
    "Summary confidence: it gives information about the overall quality of the structure. It is mainly composed by:\n",
    "\n",
    " - \"fraction_disordered\": the disorded regions are defined  in the supplementary work of AF3\n",
    "\n",
    " - \"has_clash\": indicates the proportion of clases\n",
    "\n",
    " - \"iptm\": the interface of TM scored, is calculated with the same procedure as in AF2-Multimer\n",
    "\n",
    " - \"num_recycles\": number of recycles done by the pairformer, for more information (https://elanapearl.github.io/blog/2024/the-illustrated-alphafold/)\n",
    "\n",
    " - \"ptm\": proximated TM scored, is calculated with the same procedure as in AF2-Multimer\n",
    " \n",
    " - \"ranking_score\": new score of AF3 which includes iptm, ptm, fraction_disoredred and clases to acoid hallucinations: 0.8 · ipTM + 0.2 · pTM + 0.5 · disorder − 100 · has_clash. \n",
    "\n",
    "cif models: similar to PDB, you can use programs like Chimera X and Pymol to look at it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7328da18",
   "metadata": {},
   "source": [
    "### Description of the program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ab0867",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Arial, sans-serif; line-height: 1.5; text-align: justify;\">\n",
    "   \n",
    "The analysis in the main program is divided in 6 sections:\n",
    "\n",
    "1. Libraries and initial values: It loads the libraries are needed. \n",
    "2. Paths and selected molecules: Selection of the target and the p_type\n",
    "3. Contruction of the dataframes: In this sections we extract the information of ene files and log txt in to dataframes\n",
    "4. Final Fusion and adjustments: \n",
    "5. Ranking: we calculate\n",
    "\n",
    "There are two classes of folders. Ones have the pdb from Alphafold2 and the other are obtained from AlphaFold-multimers. The difference between them is how the information about the model confidence is stored, the ones from Alphafold2 have their model confidence stored in json archives and the ones from AM have in the log.txt. This implies a different aproach of gathering this data.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430a7756",
   "metadata": {},
   "source": [
    "## Main program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158cdc73",
   "metadata": {},
   "source": [
    "### 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9f1b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File manegement\n",
    "import os, zipfile \n",
    "import re \n",
    "import shutil\n",
    "\n",
    "# Data manegement\n",
    "import pandas as pd # used to manage dataframes\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from Bio import PDB\n",
    "from Bio.PDB import MMCIFParser, PDBIO, DSSP, NeighborSearch, Superimposer, PDBParser\n",
    "from Bio.Align import PairwiseAligner\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import warnings\n",
    "\n",
    "# Subprocess to calling bash\n",
    "import subprocess # used to call bash and running external programs like pydock4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066a4adc",
   "metadata": {},
   "source": [
    "### 2. Paths and selected molecules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf408b0",
   "metadata": {},
   "source": [
    "Selection of path and molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64440d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "main_folder=\"\" # Name of\n",
    "\n",
    "directory=f\"{main_folder}/COMPLEX\"\n",
    "directory_csv= f\"{main_folder}/CSV\" # This is the the directory of the folder that will gather the outputs\n",
    "\n",
    "print(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085fb981",
   "metadata": {},
   "source": [
    "Looking at available pdbs, to see if the modeling process have be done correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d90d227",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(directory_csv):\n",
    "    os.makedirs(directory_csv)\n",
    "\n",
    "# Folders of all models\n",
    "carpetas = [nombre for nombre in os.listdir(directory) if os.path.isdir(os.path.join(directory, nombre))]\n",
    "\n",
    "#PDB files of the folders and the way we will \n",
    "archivos_pdb=[]\n",
    "patron = r'(.*(\\d+)\\.pdb$)'\n",
    "#patron = r'fold_t\\d+_b[a-z]+_a_\\d+_model_\\d+_supeimp\\.pdb' # T272\n",
    "datos_carpeta={}\n",
    "for carpeta in carpetas:  \n",
    "        patron =\"(\"+carpeta[0:4]+ \".pdb)|\" +patron\n",
    "        direccion = directory + \"/\" + carpeta + \"/\"\n",
    "        pdbs=[os.path.abspath(os.path.join(direccion, archivo)) for archivo in os.listdir(direccion) if re.match(patron, archivo)]\n",
    "        datos_carpeta={**datos_carpeta,**{carpeta:len(pdbs)}}\n",
    "        archivos_pdb.extend(pdbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6713641",
   "metadata": {},
   "outputs": [],
   "source": [
    "carpetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3137b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_carpeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576816fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numero_pdbs_by_dir(directory):  \n",
    "    x=1\n",
    "    n_archivos=0\n",
    "    for carpeta in carpetas:\n",
    "        # Accedemos a cada una de ellas y ponemos en un documento lista la dirección de cada uno de los .pdb\n",
    "        direccion = directory + \"/\" + carpeta + \"/\"\n",
    "        archivos_pdb = [archivo for archivo in os.listdir(direccion) if re.match(patron, archivo)]\n",
    "        print(x,carpeta,len(archivos_pdb))\n",
    "        n_archivos=n_archivos+len(archivos_pdb) \n",
    "        x=x+1\n",
    "    return (n_archivos)\n",
    "print(numero_pdbs_by_dir(directory))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84ffcd45",
   "metadata": {},
   "source": [
    "### 3. Data Frame creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77541622",
   "metadata": {},
   "source": [
    "#### 3.1 Description of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078f7000",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Arial, sans-serif; line-height: 1.5; text-align: justify;\">\n",
    "\n",
    "The dataframe constructed from all the following process is:\n",
    "\n",
    "Data refered to model's name\t\n",
    "- **Name**: Name of the object or element. Used to identify and merge data from different datasets.\n",
    "- **PATH**: File path associated with the object. Stores the locations of the files corresponding to each object for additional input/output operations.\n",
    "- **Complex**: Name or identifier of the studied complex.\n",
    "- **State**: State of the complex (e.g., native, mutated, etc.).\n",
    "- **Model**: Specific model used in the analysis.\n",
    "- **Rank**: Ranking of the model or complex based on a specific criterion.\n",
    "- **Version**: Version of the model or software used in the analysis.\n",
    "- **Recycle**: Number of times the model has been recycled or reused in iterations.\n",
    "- **Seed**: Seed value used by AlphaFold2.\n",
    "\n",
    "Data of pydock\n",
    "\n",
    "- **Ele**: Electrostatic energy of the complex. Measures the interaction between electric charges within the complex.\n",
    "- **Desolv**: Desolvation energy. Represents the energetic cost associated with desolvating individual molecules to form the complex.\n",
    "- **VDW**: Van der Waals energy. Measures the attractive and repulsive interactions between atoms that are not chemically bonded.\n",
    "- **Total**: Total energy of the complex. Sum of all energetic contributions (Electrostatic + Desolvation + 0.1 Van der Waals).\n",
    "- **Total2**: Unweighted total energy from pyDock (Electrostatic + Desolvation + Van der Waals).\n",
    "\n",
    "Data by Alphafold2-Multimer and AF3 log and json\n",
    "\n",
    "- **pLDDT**: Predicted Local Distance Difference Test. Measures the quality of the local structural prediction.\n",
    "- **pTM**: Predicted Template Modeling. Measures the quality of the global structural prediction based on template modeling.\n",
    "- **ipTM**: Interface Predicted Template Modeling. Measures the quality of the structural prediction at interfaces.\n",
    "- **tol**: Tolerance of the model or simulation. (only Multimer)\n",
    "- **Model_confidence**: Confidence in the predictive model. Calculated as ipTM\\*0.8 + pTM\\*0.3.\n",
    "\n",
    "Z-scores and rankinng\n",
    "\n",
    "- **MCZ-Score**: Model Confidence Z-score.\n",
    "- **PLDDTZ-Score**: pLDDT Z-score.\n",
    "- **TEZ-Score**: Z-score calculated from Total.\n",
    "- **TE2Z-Score**: Z-score calculated from Total2.\n",
    "- **Sum_Z**: Sum of the Z-scores for Model Confidence and Total.\n",
    "- **Sum2_Z**: Sum of the Z-scores for Model Confidence and Total2.\n",
    "- **Ranking_Z**: Ranking based on Sum_Z.\n",
    "- **Ranking2_Z**: Ranking based on Sum2_Z.\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"font-family: Arial, sans-serif; line-height: 1.5; text-align: justify;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b5c96a1",
   "metadata": {},
   "source": [
    "#### 3.2 Bind energy dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006ac929",
   "metadata": {},
   "source": [
    "##### 3.2.1 Extraction of the information from .ene tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8786016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty dataframe that will gather all the results\n",
    "total_df=pd.DataFrame()\n",
    "resultado_df = pd.DataFrame()\n",
    "extension_final = len(\".ene\")\n",
    "patron = r\".*\\d\\.ene$\"\n",
    "\n",
    "# Iteration of each folder, we extract all the names of the .ene inside \n",
    "for carpeta in carpetas:\n",
    "    direccion = os.path.join(directory, carpeta )\n",
    "    archivos_ene = [archivo for archivo in os.listdir(direccion) if re.match(patron, archivo)]\n",
    "    resultado_df = pd.DataFrame() # the dataframe with all the ene data of the folder, important to distinguish between Af3 and Af2-multimer\n",
    "    \n",
    "    # Interation of each .ene and extracting their information in to a single dataframe\n",
    "    for archivo in archivos_ene:\n",
    "        print(os.path.join(direccion, archivo))\n",
    "        tabla = []\n",
    "        df = pd.read_csv(os.path.join(direccion, archivo), sep='\\s+', skiprows=[1])\n",
    "        df[\"Name\"] = archivo[:-extension_final]\n",
    "        df[\"PATH\"] = os.path.join(direccion, archivo).rstrip(\".ene\")+\".pdb\"\n",
    "        print(df)\n",
    "        resultado_df = pd.concat([resultado_df, df], ignore_index=True)\n",
    "\n",
    "    # We add the information of the complex depending if the folder is from AF3\n",
    "    if carpeta.startswith('fold'):\n",
    "        resultado_df[\"Complex\"]=carpeta.split('_')[1].upper()\n",
    "    else:\n",
    "        resultado_df[\"Complex\"]=carpeta[0:4]\n",
    "    \n",
    "    # Concatenation of each  total df from each folder\n",
    "    total_df=pd.concat([total_df,resultado_df], ignore_index=True)\n",
    "   \n",
    "\n",
    "total_df.to_csv(directory_csv + \"pydock4_raw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96ca056",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e088f37",
   "metadata": {},
   "source": [
    "##### 3.2.2  Asignation of the data related to de name of the model: state, model, rank, version and recyle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33b38da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(directory_csv + \"pydock4_raw.csv\", sep=r'\\t|,')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a13b11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data_frame\n",
    "df = pd.read_csv(directory_csv + \"pydock4_raw.csv\", sep=r'\\t|,')\n",
    "\n",
    "#information to retrieve with regular expresion\n",
    "state_pattern = re.compile(r'.nrelaxed')\n",
    "version_pattern = re.compile(r\"((deepfold|alphafold2_multimer)_v\\d+)_model\")\n",
    "model_pattern = re.compile(r'model_(\\d+)')\n",
    "rank_pattern = re.compile(r'(rank_(\\d+))|(pred_\\d+)|(ranked_.*)')\n",
    "recycle_pattern = re.compile(r'(_|.)r(\\d{1,})')\n",
    "#seed_pattern = re.compile(r'seed_([0-9]+)\\.')\n",
    "#seed_pattern = re.compile(r'seed_([\\d]+)\\.')\n",
    "seed_pattern = re.compile(r'seed_([0-9]+)(?:\\.|$)')\n",
    "\n",
    "# Defining empty list where the data from the file name will be gather\n",
    "state=[]\n",
    "model=[]\n",
    "version = []\n",
    "recycle = []\n",
    "rank=[]\n",
    "seed=[]\n",
    "# Loop to gather the information entry by entry\n",
    "for linea in (df[\"Name\"].tolist()):\n",
    "    \n",
    "    #State relaxed, unrelaxed\n",
    "    match = state_pattern.search(linea)\n",
    "    if match:\n",
    "        state.append(match.group(0))\n",
    "    else:\n",
    "        state.append(\"relaxed\")\n",
    "    \n",
    "    # Model\n",
    "    match = model_pattern.search(linea)\n",
    "    if match:   \n",
    "        model.append(match.group(1)) \n",
    "    else:\n",
    "        model.append(\"cristal\")   \n",
    "    \n",
    "    #Rank\n",
    "    match = rank_pattern.search(linea)\n",
    "    if match:   \n",
    "        rank.append(match.group(0)) \n",
    "    else:\n",
    "        rank.append(\"unrank\")\n",
    "    \n",
    "    #Version \n",
    "    match = version_pattern.search(linea)\n",
    "    if match: \n",
    "        version.append(match.group(1))\n",
    "    else:\n",
    "        version.append(\"cristal\")\n",
    "    \n",
    "    # Recycle\n",
    "    match = recycle_pattern.search(linea)\n",
    "    if match:\n",
    "        recycle.append(match.group(0)[2:])\n",
    "    else:\n",
    "        recycle.append(\"Seed_0\")          \n",
    "    #Seed\n",
    "    match = seed_pattern.search(linea)\n",
    "    if match:\n",
    "        seed.append(match.group(1))\n",
    "    else:\n",
    "        seed.append(\"-\")\n",
    "\n",
    "# Adding the entries to the dataframe\n",
    "df[\"State\"]=state\n",
    "df[\"Model\"]=model\n",
    "df[\"Rank\"]=rank\n",
    "df[\"Version\"]=version\n",
    "df[\"Recycle\"]=recycle\n",
    "df[\"Seed\"]=seed\n",
    "\n",
    "# Adding additional information \n",
    "\n",
    "df.loc[df[\"Rank\"] == \"unrank\", \"Version\"] = \"alphafold3\" # Alphafold3 models \n",
    "df.loc[(df[\"Model\"] == \"cristal\") & (df[\"Rank\"] == \"unrank\"), [\"Rank\", \"Recycle\", \"State\", \"Version\"]] = \"cristal\" # Defining cristal entries \n",
    "\n",
    "# Old Alphafold2-Multimer- It may be removed\n",
    "lista_valores = [\"pred_0\", \"pred_1\", \"pred_2\", \"pred_3\", \"pred_4\", \"pred_5\"]\n",
    "df.loc[df[\"Rank\"].isin(lista_valores), \"Version\"] = \"Alphafold2\"\n",
    "\n",
    "# To have more available the path for possible future accesion\n",
    "df['Name']= df['Name']+\".pdb\"\n",
    "\n",
    "# Añadimos informacion de los ranked- Unrelevant information, it may be removed\n",
    "df.loc[(df[\"Model\"] == \"cristal\") & (df[\"Rank\"] != \"cristal\"),  \"Version\"] = \"Alphafold2\"\n",
    "df.loc[(df[\"Model\"] == \"cristal\") & (df[\"Rank\"] != \"cristal\"), [\"Model\",  \"Recycle\"]] = \"ranked\"\n",
    "\n",
    "#The models were all relaxed since we used AMBER in openMM\n",
    "df[\"State\"]=\"relaxed\"\n",
    "\n",
    "df_pydock=df\n",
    "df_pydock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b692fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pydock.to_csv(directory_csv+'/pydock4_all.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a72566e0",
   "metadata": {},
   "source": [
    "#### 3.3 Log.txt information retrieving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bcec9c",
   "metadata": {},
   "source": [
    "The information related to the pLDDT, pTM, ipTM and tol will be gathered in a single dataframe that will be merged with df_pydock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e1fc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pydock\n",
    "# Folders of all models\n",
    "carpetas_log = [nombre for nombre in os.listdir(directory) if os.path.isdir(os.path.join(directory, nombre))]\n",
    "#carpetas_log.remove('Version1')\n",
    "carpetas_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0af9abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe columns\n",
    "columns = [\"Complex\",\"Model\",\"State\",'Version', 'Recycle', 'pLDDT', 'pTM', 'ipTM', 'tol','Seed']\n",
    "\n",
    "# Patrons in the text to gather the information\n",
    "#complex_pattern = re.compile(r'((T|t)\\/.*_A)') \n",
    "rank_pattern = re.compile(r'(rank_(\\d+))|(pred_\\d+)|(ranked_.*)')\n",
    "model_pattern = re.compile(r'model_(\\d+)')\n",
    "state_pattern = re.compile(r'rank')\n",
    "version_pattern = re.compile(r\"((deepfold|alphafold2_multimer)_v\\d+)_model\")\n",
    "recycle_pattern = re.compile(r'recycle=(\\d+)')\n",
    "plddt_pattern = re.compile(r'pLDDT=([\\d.]+)')\n",
    "ptm_pattern = re.compile(r'pTM=([\\d.]+)')\n",
    "iptm_pattern = re.compile(r'ipTM=([\\d.]+)')\n",
    "tol_pattern = re.compile(r'tol=([\\d.]+)')\n",
    "seed_pattern = re.compile(r'seed_([\\d.]+)')\n",
    "name_pattern = re.compile(r\"(fold_t\\d+_\\d+_model_\\d+)\")\n",
    "df_log=pd.DataFrame()\n",
    "\n",
    "for carpeta in carpetas_log:\n",
    "    directory_log=f\"{directory}/{carpeta}/log.txt\"\n",
    "    # Loading the archive\n",
    "    with open(directory_log, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Value extraction\n",
    "    #name = None\n",
    "    complex=None\n",
    "    model=None\n",
    "    version = None\n",
    "    state=None\n",
    "    recycle = None\n",
    "    plddt = None\n",
    "    ptm = None\n",
    "    iptm = None\n",
    "    tol = None\n",
    "    seed = None\n",
    "    data=[]\n",
    "    for line in lines:\n",
    "        \n",
    "        # # Complex\n",
    "        # match = complex_pattern.search(line)\n",
    "        # if match:\n",
    "        #     print()\n",
    "        #     complex = match.group(0)\n",
    "        #     complex=complex[2:-2]\n",
    "\n",
    "        #Name\n",
    "        # match = name_pattern.search(line)\n",
    "        # if match:\n",
    "        #     name = match.group(1)+'.pdb'\n",
    "        # else:\n",
    "        #     name =directory_log \n",
    "        #State\n",
    "        match = state_pattern.search(line)\n",
    "        if match:\n",
    "            state=\"relaxed\"\n",
    "        else:\n",
    "            state=\"unrelaxed\"\n",
    "\n",
    "        # Model\n",
    "        match = model_pattern.search(line)\n",
    "        if match:\n",
    "            model= match.group(1)\n",
    "        \n",
    "        # Version\n",
    "        match = version_pattern.search(line)\n",
    "        if match:\n",
    "            version = match.group(1)\n",
    "        else:\n",
    "            version = 'alphafold3'\n",
    "            \n",
    "        # Recycle\n",
    "        match = recycle_pattern.search(line)\n",
    "        if match:\n",
    "            recycle = match.group(1)\n",
    "        else:\n",
    "            recycle = 'Seed_0'\n",
    "        \n",
    "        #  pLDDT\n",
    "        match = plddt_pattern.search(line)\n",
    "        if match:\n",
    "            plddt = match.group(1)\n",
    "        else:\n",
    "            plddt = None\n",
    "        \n",
    "        #  pTM\n",
    "        match = ptm_pattern.search(line)\n",
    "        if match:\n",
    "            ptm = match.group(1)\n",
    "        else:\n",
    "            ptm=None\n",
    "        \n",
    "        #  ipTM\n",
    "        match = iptm_pattern.search(line)\n",
    "        if match:\n",
    "            iptm = match.group(1)\n",
    "        else:\n",
    "            iptm=None\n",
    "        \n",
    "        #  tol\n",
    "        match = tol_pattern.search(line)\n",
    "        if match:\n",
    "            tol = match.group(1)\n",
    "        else:\n",
    "            tol=\"-\"\n",
    "        \n",
    "        #seed\n",
    "        match = seed_pattern.search(line)\n",
    "        if match:\n",
    "            seed = match.group(1)\n",
    "        else:\n",
    "            seed=\"-\"\n",
    "        \n",
    "        # rank\n",
    "        match = rank_pattern.search(line)\n",
    "        if match:   \n",
    "            recycle = 'Seed_0'\n",
    "        # Guardar los valores en el DataFrame\n",
    "        data.append([complex,model,state,version, recycle, plddt, ptm, iptm, tol,seed])\n",
    "\n",
    "    # Crear el DataFrame\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    # Model Conficende calculated as AF2-Multimer paper\n",
    "    df['ipTM'] = pd.to_numeric(df['ipTM'], errors='coerce')\n",
    "    df['pTM'] = pd.to_numeric(df['pTM'], errors='coerce')\n",
    "    df['Model_confidence'] = 0.8 * df['ipTM'] + 0.2 * df['pTM']\n",
    "    if carpeta.startswith('fold'):\n",
    "        df[\"Complex\"]=carpeta.split('_')[1].upper()\n",
    "    else:\n",
    "        df[\"Complex\"]=carpeta[0:4]\n",
    "    df = df.dropna(subset=['Model_confidence'])\n",
    "    df['pLDDT'] = pd.to_numeric(df['pLDDT'], errors='coerce')\n",
    "\n",
    "    # Ensambling the df_log to gather all the information\n",
    "    df_log=pd.concat([df_log,df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aef76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The models were all relaxed\n",
    "df_log[\"State\"]=\"relaxed\"\n",
    "df_log.to_csv(directory_csv+'/log_all.csv', index=False)\n",
    "df_log"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24f4d664",
   "metadata": {},
   "source": [
    "### 4.  Final fusion and Adjusments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44be3403",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Arial, sans-serif; line-height: 1.5; text-align: justify;\">Now we ensemble a new_dataframe to collect all the data obtained during the calculation of for a posterior statistical analysis\n",
    "\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ffa3f3a",
   "metadata": {},
   "source": [
    "#### 4.1 Checking for possible issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d11e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataframes\n",
    "df_pydock =pd.read_csv(directory_csv+'/pydock4_all.csv')\n",
    "df_log=pd.read_csv(directory_csv+'/log_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca0d4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22307bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pydock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1e77c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Checking for the length of dataframes, the should match, if not revised\n",
    "unicos=set(df_pydock[\"Complex\"])\n",
    "for complejo in unicos:\n",
    "    print(complejo)\n",
    "    n_pydock=len(df_pydock[df_pydock[\"Complex\"]==complejo])\n",
    "    n_log=len(df_log[df_log[\"Complex\"]==complejo])\n",
    "    print(\"Pydock:\",n_pydock, \" Log:\",n_log,\"Difference:\",n_pydock-n_log)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb6c7f24",
   "metadata": {},
   "source": [
    "#### 4.2 Merging dataframes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29c9bf0e",
   "metadata": {},
   "source": [
    "Determaining which columns are diferent and merging by the common ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ed674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the  shared columns\n",
    "columna4=(df_pydock.columns).tolist()\n",
    "columna3=(df_log.columns).tolist()\n",
    "compartidos2=list(set(columna4).intersection(columna3))\n",
    "\n",
    "# Coercing to have the same type\n",
    "df_pydock[compartidos2]=df_pydock[compartidos2].astype(str)\n",
    "df_log[compartidos2]=df_log[compartidos2].astype(str)\n",
    "\n",
    "# Merging the values\n",
    "merged_df2 = df_pydock.merge(df_log, on= compartidos2, how='left')\n",
    "print (compartidos2)\n",
    "\n",
    "# Savind the results\n",
    "merged_df2.to_csv(directory_csv+'/merged_df2.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38c76b3",
   "metadata": {},
   "source": [
    "### 5. Ranking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27adfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm=pd.read_csv(directory_csv+'/merged_df2.csv')\n",
    "df_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0740d84b",
   "metadata": {},
   "source": [
    "Z-score of pydock and Model confidence of the selected models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbf2ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing unnecesary columns\n",
    "columnas=['Conf','RANK']\n",
    "df_norm.drop(columnas, axis=1, inplace=True)\n",
    "df_norm.dropna(subset=[\"Complex\"],inplace=True)\n",
    "\n",
    "# Removing duplicates\n",
    "df_norm=df_norm.drop_duplicates(subset=[\"Name\"],keep=\"first\")\n",
    "duplicados = df_norm[df_norm.duplicated(subset=[\"Name\",\"Version\",\"Complex\",\"Recycle\",\"State\"])]\n",
    "\n",
    "# Adding Total2 column\n",
    "df_norm[\"Total2\"]=df_norm[\"VDW\"]+df_norm[\"Ele\"]+df_norm[\"Desolv\"] \n",
    "\n",
    "# Z-Score individuales, inicializacion\n",
    "df_norm[\"MCZ-Score\"] = 0 # Z-score de model_conficence\n",
    "df_norm[\"PLDDTZ-Score\"] = 0 # Z-score de pLDDT\n",
    "df_norm[\"TEZ-Score\"] = 0 # Z-score de Total\n",
    "df_norm[\"TE2Z-Score\"] = 0 # Z-score de Total2\n",
    "\n",
    "# Suma de Z-Score, inicialicion\n",
    "df_norm[\"Sum_Z\"] = 0 # Z-score Model confidence + Total\n",
    "df_norm[\"Sum2_Z\"] = 0 # Z-score Model confidence + Total2\n",
    "df_norm[\"Z-PLT\"] = 0 # Z-score de pLDDT + Total\n",
    "df_norm[\"Z-PLT2\"]= 0 # Z-score de pLDDT + Total2\n",
    "\n",
    "# Ranking Z-Score, inicializacion\n",
    "df_norm[\"Ranking_Z\"] = 0 # Ranking de Sum_Z\n",
    "df_norm[\"Ranking2_Z\"] = 0 # Ranking de Sum2_Z\n",
    "df_norm[\"Ranking_PLT\"] = 0 # Ranking de Z-PLT\n",
    "df_norm[\"Ranking_PLT2\"] = 0 # Ranking de Z-PLT2\n",
    "\n",
    "# Calculo de medias y desviaciones segun complejo\n",
    "grouped = df_norm.groupby([\"Complex\"])\n",
    "medias=grouped.mean()\n",
    "sdesv=grouped.std()\n",
    "\n",
    "# Z-Score individuales\n",
    "for name, group in grouped:\n",
    "    # Calculamos Z_score de model_conficence y total energy\n",
    "    df_norm.loc[group.index,[\"MCZ-Score\"]] = (group[\"Model_confidence\"]-medias.loc[name,\"Model_confidence\"])/sdesv.loc[name,\"Model_confidence\"]\n",
    "    df_norm.loc[group.index,[\"TEZ-Score\"]] = (group[\"Total\"]-medias.loc[name,\"Total\"])/sdesv.loc[name,\"Total\"]\n",
    "    df_norm.loc[group.index,[\"TE2Z-Score\"]] = (group[\"Total2\"]-medias.loc[name,\"Total2\"])/sdesv.loc[name,\"Total2\"]\n",
    "    df_norm.loc[group.index,[\"PLDDTZ-Score\"]] = (group[\"pLDDT\"]-medias.loc[name,\"pLDDT\"])/sdesv.loc[name,\"pLDDT\"]\n",
    "\n",
    "# Suma de Z-Score\n",
    "df_norm.loc[:,\"Sum_Z\"]=df_norm.loc[:,\"MCZ-Score\"]-df_norm.loc[:,\"TEZ-Score\"]\n",
    "df_norm.loc[:,\"Sum2_Z\"]=df_norm.loc[:,\"MCZ-Score\"]-df_norm.loc[:,\"TE2Z-Score\"]\n",
    "df_norm.loc[:,\"Z-PLT\"]=df_norm.loc[:,\"PLDDTZ-Score\"]-df_norm.loc[:,\"TEZ-Score\"]\n",
    "df_norm.loc[:,\"Z-PLT2\"]=df_norm.loc[:,\"PLDDTZ-Score\"]-df_norm.loc[:,\"TE2Z-Score\"]\n",
    "\n",
    "# Ranking Z-Score\n",
    "for name, group in grouped:\n",
    "    df_norm.loc[group.index,\"Ranking_Z\"]=df_norm.loc[group.index,\"Sum_Z\"].rank(ascending=False)\n",
    "    df_norm.loc[group.index,\"Ranking2_Z\"]=df_norm.loc[group.index,\"Sum2_Z\"].rank(ascending=False)\n",
    "    df_norm.loc[group.index,\"Ranking_PLT\"]=df_norm.loc[group.index,\"Z-PLT\"].rank(ascending=False)\n",
    "    df_norm.loc[group.index,\"Ranking_PLT2\"]=df_norm.loc[group.index,\"Z-PLT2\"].rank(ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e6528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86e8aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm.to_csv(directory_csv + \"/df_norm_.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
