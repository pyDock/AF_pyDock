{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictors Modeling and Energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides the code to:\n",
    "\n",
    "1. Model with Alphafold2-Multimer the desired target given a fasta file\n",
    "\n",
    "2. Relax the models created Alphafold2-Multimer\n",
    "\n",
    "3. Extract, convert and create a pseudo-log.txt from AF3 models\n",
    "\n",
    "4. Calculate the bind Energy of Alphafold2-Multimer and AF3 models\n",
    "\n",
    "There are two alternative codes A and B. A is for Local calculations and B for calculations using MN5 (Cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings of the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File manegement\n",
    "import os, zipfile \n",
    "import re \n",
    "import shutil\n",
    "\n",
    "# Data manegement\n",
    "import pandas as pd # used to manage dataframes\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from Bio import PDB\n",
    "from Bio.PDB import MMCIFParser, PDBIO, DSSP, NeighborSearch,Superimposer,PDBParser\n",
    "from Bio.Align import PairwiseAligner\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import warnings\n",
    "# Subprocess to calling bash\n",
    "import subprocess # used to call bash and running external programs like pydock4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target election and p_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you choose:\n",
    "\n",
    "- The target.\n",
    "\n",
    "- The template to copy the existing scripts.\n",
    "\n",
    "- The folder where we collect the fastas for modeling.\n",
    "\n",
    "- The test settings (Predictors or Scorers) and whether it is local or on MareNostrum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicion del directorio principal\n",
    "dir_capri=\"/home/vicmonhon/Desktop/Automatizacion/Automatizacion\"\n",
    "\n",
    "#Plantilla  \n",
    "nplantilla=\"T901\" \n",
    "\n",
    "# Seleccion de target\n",
    "target=\"T902\" \n",
    "\n",
    "### Settings\n",
    "p_type= \"Predictors\"\n",
    "local=True # important to execute the code in local or a server\n",
    "\n",
    "# Definicion de directorios\n",
    "fasta_dir=os.path.join(dir_capri,\"fastas\") # Where the fastas are gatherer\n",
    "dir_target=os.path.join(dir_capri,target) # Directory of the complete target\n",
    "dir_template=os.path.join(dir_capri,nplantilla)# Template with all the necesary scripts\n",
    "dir_complex=f\"{dir_target}/Predictors/AF_MODELS/COMPLEX\" # This directory is needed to execute several codes\n",
    "\n",
    "# Definicion de archivos fasta\n",
    "original_fasta=f\"{fasta_dir}/{target}.fasta\"\n",
    "fasta=f\"{dir_complex}/{target}.fasta\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of the target folder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente bloque copiamos la plantilla, con un nuevo nombre. Después el fasta de la carpeta donde se almacenan (fasta_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ya existe la carpeta\n",
      "Archivo localizado en /home/vicmonhon/Desktop/Automatizacion-20240704T102446Z-001/Automatizacion/fastas_alba/T902.fasta copiado exitosamente a /home/vicmonhon/Desktop/Automatizacion-20240704T102446Z-001/Automatizacion/T902/Predictors/AF_MODELS/COMPLEX/T902.fasta\n",
      "Archivo existente /home/vicmonhon/Desktop/Automatizacion-20240704T102446Z-001/Automatizacion/T902/Predictors/AF_MODELS/COMPLEX/T902.fasta\n"
     ]
    }
   ],
   "source": [
    "# First, ensure that the fasta file is in fasta_dir\n",
    "\n",
    "# Create the target folder with all the scripts from the template if the fasta exists\n",
    "if not os.path.exists(dir_target):\n",
    "    shutil.copytree(dir_template, dir_target)\n",
    "    print(f\"Folder created: {dir_target}\")\n",
    "else:\n",
    "    print(\"The folder already exists\")\n",
    "\n",
    "if os.path.exists(original_fasta):\n",
    "    shutil.copy2(original_fasta, fasta)\n",
    "    print(f\"File {original_fasta} copied to {fasta}\") \n",
    "else: \n",
    "    print(f\"The fasta doesn't exist in {original_fasta} or {dir_target} doesn't exist\")\n",
    "    assert False, f\"Place the fasta file in {fasta_dir}\"\n",
    "\n",
    "# Ensure that the file is inside the target folder\n",
    "# Remember that the original_fasta needs to be in fasta_dir to copy correctly\n",
    "\n",
    "if os.path.exists(fasta):\n",
    "    print(\"Existing file\", fasta)\n",
    "else: \n",
    "    print(\"File does not exist\", fasta)\n",
    "    assert False, f\"Warning, the file was not copied correctly, fasta is not in {fasta}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"Template copied, now go to local or to server\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Local Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Alphafold2-Multimer modeling (LOCAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash:  conda activate Alphafold2\n",
      ": No such file or directory\n"
     ]
    }
   ],
   "source": [
    "if local:\n",
    "    print(\"local\")\n",
    "    subprocess.run(['bash',\"conda activate Alphafold2\\n\",\"bash ./script_calculo_local.sh\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Relaxation (LOCAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vicmonhon/Desktop/Automatizacion-20240704T102446Z-001/Automatizacion/T902/Predictors/AF_MODELS/COMPLEX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vicmonhon/Desktop/Automatizacion-20240704T102446Z-001/Automatizacion/T902/Predictors/AF_MODELS/COMPLEX/T902.colabfold.relax.cmd: line 2: greasy: command not found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "\n",
    "def relaxation(dir_complex, target):\n",
    "\n",
    "\n",
    "    greasy = 'greasy'\n",
    "    colabfold_relax = 'colabfold_relax'\n",
    "    \n",
    "    # Creation of each command of relaxation to pass to shell script\n",
    "    os.chdir(dir_complex)\n",
    "    print(os.getcwd())\n",
    "    os.chdir('..')\n",
    "    complex_dir = os.getcwd()\n",
    "    fasta_files = glob.glob(os.path.join(complex_dir, '*.fasta'))\n",
    "    for fasta_file in fasta_files:\n",
    "        base_name = os.path.basename(fasta_file).replace('.fasta', '')\n",
    "        cmd_file = os.path.join(complex_dir, f'{base_name}.colabfold.relax.cmd')\n",
    "        \n",
    "        with open(cmd_file, 'w') as cmd_fp:\n",
    "            cmd_fp.write(f'#!/bin/bash\\n{greasy} {base_name}.colabfold.relax.greasy\\n')\n",
    "        \n",
    "        pdb_files = glob.glob(os.path.join(complex_dir, 'T*_*.r*.pdb'))\n",
    "        \n",
    "        with open(cmd_file, 'a') as cmd_fp:\n",
    "            for pdb_file in pdb_files:\n",
    "                cmd_fp.write(f\"{colabfold_relax} --max-iterations 2000 --tolerance 2.39 --stiffness 10.0 --max-outer-iterations 3 --use-gpu {pdb_file} {pdb_file.replace('/COMPLEX', '')}\\n\")\n",
    "\n",
    "    # Relaxation execution\n",
    "    os.environ['GREASY_NWORKERS'] = '2' # change if you need more, keep in mind that more workers could lead to abortion of execution\n",
    "    os.chdir(complex_dir)\n",
    "    file_path=f'{os.getcwd()}/COMPLEX/{target}.colabfold.relax.cmd'# Check if the file is correcly created\n",
    "    return file_path\n",
    "   \n",
    "file_path=relaxation(dir_complex, target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that CMD is correctly generated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd= open(file_path)\n",
    "content= cmd.read()\n",
    "print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"Look at the script, comment this line if you don't want to pause the execution\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution of the relaxation\n",
    "subprocess.run(['bash', file_path])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. AF3 models processing (LOCAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation of Alphafold3 Models\n",
    "1. Decompression\n",
    "\n",
    "2. Conversion to PDB\n",
    "\n",
    "3. Extraction of data from the JSON: iptm and ptm to save the model confidence in an artificial log.txt, similar to the one from Alphafold Multimer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Decompression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 4px solid; background-color:#FF6347; color: #FFFFFF; padding: 10px;\">\n",
    "    <strong style=\"color: #FF6347;\">Nota:</strong>\n",
    "    <span style=\"color: #000000;\">WARNING: rebember to download the AF3 models and have them in the dir_complex</span>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncompress the AlphaFold3 Job.\n",
    "def descomprimir_archivo(zip_path, directorio_destino):\n",
    "\n",
    "    # Ensure that the destination directory exists; if not, create it\n",
    "    if not os.path.exists(directorio_destino):\n",
    "        os.makedirs(directorio_destino)\n",
    "\n",
    "    # Open the ZIP file in read mode\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        # Extract all files into the specified directory\n",
    "        zip_ref.extractall(directorio_destino)\n",
    "\n",
    "patron = r'(.*(\\d+)\\.zip$)'\n",
    "patron_CIF = r'(.*(\\d+)\\.cif$)'\n",
    "\n",
    "zipfiles = [os.path.abspath(os.path.join(dir_complex, archivo)) for archivo in os.listdir(dir_complex) if re.match(patron, archivo)]\n",
    "print(zipfiles)\n",
    "for zipfille in zipfiles:\n",
    "    print(zipfille)\n",
    "    descomprimir_archivo(zipfille, zipfille.rstrip('.zip'))\n",
    "\n",
    "CIF_files = [os.path.abspath(os.path.join(dir_complex, archivo)) for archivo in os.listdir(zipfille.rstrip('.zip')) if re.match(patron_CIF, archivo)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Conversion to PDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert CIF files to PDB files of the AplhaFold3 Job.\n",
    "def convert_cif_to_pdb(cif_file, pdb_file):\n",
    "    \"\"\"\n",
    "    Convert a CIF file to a PDB file using Biopython.\n",
    "\n",
    "    Parameters:\n",
    "    cif_file (str): Path to the input CIF file.\n",
    "    pdb_file (str): Path to the output PDB file.\n",
    "    \"\"\"\n",
    "    parser = MMCIFParser()\n",
    "    structure = parser.get_structure('ID', cif_file)\n",
    "    io = PDBIO()\n",
    "    io.set_structure(structure)\n",
    "    io.save(pdb_file)\n",
    "\n",
    "patron_CIF = r'(.*(\\d+)\\.cif$)'\n",
    "for zipfille in zipfiles:\n",
    "    CIF_files = [os.path.join(zipfille.rstrip('.zip'),archivo) for archivo in os.listdir(zipfille.rstrip('.zip')) if re.match(patron_CIF, archivo)]\n",
    "    #print(CIF_files)\n",
    "    for CIF_file in CIF_files:\n",
    "        #print(CIF_file)\n",
    "        convert_cif_to_pdb(CIF_file, CIF_file.replace('.cif','.pdb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 JSON data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the Json\n",
    "import os\n",
    "import json\n",
    "\n",
    "def leer_json_extract_vars(directorio, claves):\n",
    "    \"\"\"\n",
    "    Lee archivos JSON en un directorio específico y extrae las variables especificadas.\n",
    "    \n",
    "    Parámetros:\n",
    "    directorio (str): Ruta al directorio que contiene los archivos JSON.\n",
    "    claves (list): Lista de claves a extraer de los archivos JSON.\n",
    "    \n",
    "    Retorna:\n",
    "    dict: Diccionario con nombres de archivo y sus variables extraídas.\n",
    "    \"\"\"\n",
    "    resultados = {}  # Diccionario para almacenar los resultados\n",
    "\n",
    "    # Recorrer todos los archivos en el directorio\n",
    "    pattern_json = re.compile(r\"summary_confidences_\\w\\.json$\")\n",
    "    for archivo in os.listdir(directorio):\n",
    "        if pattern_json.search(archivo):  # Asegurarse de que es un archivo JSON\n",
    "            ruta_completa = os.path.join(directorio, archivo)\n",
    "            with open(ruta_completa, 'r') as f:\n",
    "                data = json.load(f)  # Cargar el contenido JSON\n",
    "                # Extraer las variables especificadas\n",
    "                valores_extraidos = {clave: data.get(clave, None) for clave in claves}\n",
    "                \n",
    "                # Almacenar los resultados\n",
    "                resultados[archivo] = valores_extraidos\n",
    "\n",
    "    return resultados\n",
    "\n",
    "# Usar la función\n",
    "claves_a_extraer = ['ptm', 'iptm']  # Añadir aquí cualquier clave que necesites\n",
    "for zipfille in zipfiles:\n",
    "    log_folder = zipfille.rstrip('.zip')\n",
    "    resultados = leer_json_extract_vars(zipfille.rstrip('.zip'), claves_a_extraer)\n",
    "    with open(os.path.join(log_folder,'log.txt'), 'w') as file:\n",
    "        for archivo, vars in resultados.items():\n",
    "            # Formatear nombre del archivo y eliminar partes no deseadas\n",
    "            nombre_archivo_formateado = archivo.replace('summary_confidences', 'model').rstrip('.json')\n",
    "            # Crear una cadena de texto con los pares clave=valor\n",
    "            vars_text = ' '.join([f\"{key.replace('tm','TM')}={value}\" for key, value in vars.items()])\n",
    "            file.write(f\"{nombre_archivo_formateado} {vars_text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subprocess.run(['bash',f\"scp -r fold_t282_1 bsc054620@glogin1.bsc.es:/gpfs/projects/bsc54/Capri/{target}/Predictors/AF_MODELS/COMPLEX/\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. pyDock Bind Energy (Local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Ligand and receptor asignation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "multip=True\n",
    "if multip:\n",
    "    script_content=\"\"\"\n",
    " #!/bin/bash\n",
    "        #rm Greasy_BindE_mul_ligs.txt;\n",
    "        CHAINS_LIG_VALUES=(\n",
    "            \"B,C,D A\"\n",
    "            \"A,C,D B\"\n",
    "            \"A,B,D C\"\n",
    "            \"A,B,C D\"\n",
    "            \"A E,G\"\n",
    "            \"B I,K\"\n",
    "            \"C F,H\"\n",
    "            \"D J,L\"\n",
    "        )\n",
    "\n",
    "        for h in $(ls -d  T*cola*/ fold*/);do\n",
    "                echo $h;\n",
    "                cd $h;\n",
    "                for j in *.pdb;do\n",
    "                        echo $j\n",
    "                        for value in \"${CHAINS_LIG_VALUES[@]}\"; do\n",
    "                    CHAINS_LIG=\"$value\"\n",
    "                    LIG=echo $CHAINS_LIG | cut -d\" \" -f 2\n",
    "                            REC=echo $CHAINS_LIG | cut -d\" \" -f 1\n",
    "                            CH=${LIG/,}\n",
    "                            echo -e \"[receptor]\\npdb         = $j\\nmol         = $REC\\nnewmol      = $REC\" > ${j/.pdb}_LIG_${CH}.ini;\n",
    "                            echo -e \"[ligand]\\npdb         = $j\\nmol         = $LIG\\nnewmol      = $LIG\" >>  ${j/.pdb}_LIG_${CH}.ini;\n",
    "                            #echo -e \"[reference]\\npdb         = ranked_0_REF.pdb\\nrecmol      = $REC\\nligmol      = $LIG\\nnewrecmol   = $REC\\nnewligmol   = $LIG\\n\" >> ${j/.pdb}_LIG_${CH}.ini;\n",
    "                            echo \"cd ${h}; timeout 5m pydock4 ${j/.pdb}_LIG_${CH} bindEy;cd -\" >> ../Greasy_BindE_mul_ligs.txt;\n",
    "                done\n",
    "                done\n",
    "                cd -;\n",
    "        done\n",
    "        \"\"\"\n",
    "\n",
    "    comando=f\"cd {dir_complex}\\n bash {script_content}\"\n",
    "    #subprocess.run(['bash',f\"{comando}\"])\n",
    "else:\n",
    "    comando=f\"cd {dir_complex}\\n bash ./ini_creator_bindE.sh\"\n",
    "    subprocess.run(['bash',f\"{comando}\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Bind Energy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comando=f\"cd {dir_complex}\\n bash ./script_calculo_local.sh\"\n",
    "if local:\n",
    "    subprocess.run(['bash', f\"{comando}\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Energy summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comando=f\"cd {dir_complex}\\n bash ./sum_ene_multy_bindEy_new.sh\"\n",
    "if local:\n",
    "    subprocess.run(['bash',f\"{comando}\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B Marenostrum method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1  Alphafold2-Multimer Modeling (MN5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. MSA creation for Alphafold2-Multimer\n",
    "El Script Correr_Alphafold2.sh que se ejecutará en MareNostrum para iniciar el modelado de AF-Multimer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 MSA creation for MN5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/vicmonhon/Desktop/Automatizacion/Automatizacion/T902/Predictors/AF_MODELS/COMPLEX'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconda activate Alphafold2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcommand\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;66;03m#subprocess.run(['bash',command])\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[43mMSA_AF_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_complex\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 19\u001b[0m, in \u001b[0;36mMSA_AF_creator\u001b[0;34m(dir_complex)\u001b[0m\n\u001b[1;32m     17\u001b[0m             commands\u001b[38;5;241m.\u001b[39mappend(cmd)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_complex\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.fasta\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     21\u001b[0m             i_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOMPLEX\u001b[39m\u001b[38;5;124m'\u001b[39m, i)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/vicmonhon/Desktop/Automatizacion/Automatizacion/T902/Predictors/AF_MODELS/COMPLEX'"
     ]
    }
   ],
   "source": [
    "def MSA_AF_creator(dir_complex):\n",
    "    commands = []\n",
    "    versions = ['v2', 'v3']\n",
    "    for h in versions:\n",
    "        if h == 'v3':\n",
    "            for i in os.listdir(dir_complex):\n",
    "                if i.endswith('.fasta'):\n",
    "                    i_path = os.path.join(os.getcwd(), 'COMPLEX', i)\n",
    "                    output_path = os.path.join(os.getcwd(), 'COMPLEX', f\"{os.path.basename(i).replace('.fasta', '')}.colabfold.{h}\")\n",
    "                    cmd = (\n",
    "                        f\"colabfold_batch {i_path} {output_path} \"\n",
    "                        f\"--msa-only --num-seeds 2 --save-recycles \"\n",
    "                        f\"--model-type alphafold2_multimer_{h} \"\n",
    "                        f\"--recycle-early-stop-tolerance 0 --rank multimer \"\n",
    "                        f\"--use-dropout --num-recycle 20 --amber --use-gpu-relax\"\n",
    "                    )\n",
    "                    commands.append(cmd)\n",
    "        else:\n",
    "            for i in os.listdir(dir_complex):\n",
    "                if i.endswith('.fasta'):\n",
    "                    i_path = os.path.join(os.getcwd(), 'COMPLEX', i)\n",
    "                    output_path = os.path.join(os.getcwd(), 'COMPLEX', f\"{os.path.basename(i).replace('.fasta', '')}.colabfold.{h}\")\n",
    "                    cmd = (\n",
    "                        f\"colabfold_batch {i_path} {output_path} \"\n",
    "                        f\"--msa-only --save-recycles \"\n",
    "                        f\"--model-type alphafold2_multimer_{h} \"\n",
    "                        f\"--recycle-early-stop-tolerance 0 --rank multimer \"\n",
    "                        f\"--use-dropout --num-recycle 20 --amber --use-gpu-relax\"\n",
    "                    )\n",
    "                    commands.append(cmd)\n",
    "\n",
    "    for command in commands:\n",
    "        print(\"conda activate Alphafold2\\n\",f\"{command}\")\n",
    "        #subprocess.run(['bash',command])\n",
    "\n",
    "MSA_AF_creator(dir_complex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Creation of the Script Correr_Alphafold2.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_content = f\"\"\"\\\n",
    "cd capri/{target}/Predictors/AF_MODELS\n",
    "colabfold_batch='/home/bsc/bsc054620/projects/apps/localcolabfold/colabfold-conda/bin/colabfold_batch'\n",
    "for h in v2 v3 ; do\n",
    "\n",
    "    for i in COMPLEX/*fasta ;do\n",
    "\n",
    "        l=`head $i| awk '{{split($2,a,\"|\");print a[1]}}'| xargs | sed 's/ /_/g'`;\n",
    "\n",
    "        echo '#!/bin/bash\n",
    "#SBATCH --job-name='$(basename ${{i/.fasta}})'.colabfold.'$h'\n",
    "#SBATCH -D .\n",
    "#SBATCH --output='$(basename ${{i/.fasta}})'.colabfold.'$h'.out\n",
    "#SBATCH --error='$(basename ${{i/.fasta}})'.colabfold.'$h'.err\n",
    "#SBATCH --ntasks=20\n",
    "#SBATCH --time=07:00:00 #2-00:00:00 # Dos dias max.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --qos=acc_bscls\n",
    "#SBATCH --account=bsc54\n",
    "module load cuda' > `dirname ${{i}}`/`basename ${{i/.fasta}}`.colabfold.$h.cmd;\n",
    "        if [ $h == 'v3' ];then\n",
    "\n",
    "            echo $colabfold_batch `pwd`/$i `pwd`/COMPLEX/`basename ${{i/.fasta}}`.colabfold.$h --save-recycles --num-seeds 2 --model-type alphafold2_multimer_$h --recycle-early-stop-tolerance 0 --rank multimer --use-dropout --num-recycle 20 --amber --use-gpu-relax >> `dirname ${{i}}`/`basename ${{i/.fasta}}`.colabfold.$h.cmd;\n",
    "        else\n",
    "            echo $colabfold_batch `pwd`/$i `pwd`/COMPLEX/`basename ${{i/.fasta}}`.colabfold.$h --save-recycles --model-type alphafold2_multimer_$h --recycle-early-stop-tolerance 0 --rank multimer --use-dropout --num-recycle 20 --amber --use-gpu-relax >> `dirname ${{i}}`/`basename ${{i/.fasta}}`.colabfold.$h.cmd;\n",
    "        fi\n",
    "    done;\n",
    "done\n",
    "\n",
    "cd Complex\n",
    "# sbatch {target}.colabfold.v2.cmd\n",
    "# sbatch {target}.colabfold.v3.cmd\n",
    "# squeue\n",
    "\"\"\"\n",
    "\n",
    "with open(f'f\"{dir_target}/Predictors/AF_MODELS/COMPLEX\"/Correr_Alphafold2.sh', 'w') as file:\n",
    "    file.write(script_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Uploading the archives to MN5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following printed command with subprocess or in a terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 4px solid #1E90FF; background-color: #6FA8DC; color: #FFFFFF; padding: 10px;\">\n",
    "    <strong style=\"color: #1E90FF;\">NOTE: </strong>\n",
    "    <span style=\"color: #000000;\"> You can open the integrated terminal in VS Code by pressing `Ctrl+`` (the backtick key, which is located below the escape key on most keyboards).\n",
    "    </span>\n",
    "</div>\n",
    "<div style=\"border-left: 4px solid #1E90FF; background-color: #6FA8DC; color: #FFFFFF; padding: 10px;\">\n",
    "    <span style=\"color: #000000;\">  Open a terminal and introduce the following commands</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introduce the following commnads in a terminal\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MSA_AF_creator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# if not local:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIntroduce the following commnads in a terminal\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mMSA_AF_creator\u001b[49m(dir_complex)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#subprocess.run(['bash',f\"scp {dir_target} bsc054620@glogin1.bsc.es:/gpfs/projects/bsc54/Capri/\"])\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscp \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdir_target\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m bsc054620@glogin1.bsc.es:/gpfs/projects/bsc54/Capri/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MSA_AF_creator' is not defined"
     ]
    }
   ],
   "source": [
    "# if not local:\n",
    "print(\"Introduce the following commnads in a terminal\")\n",
    "MSA_AF_creator(dir_complex)\n",
    "#subprocess.run(['bash',f\"scp {dir_target} bsc054620@glogin1.bsc.es:/gpfs/projects/bsc54/Capri/\"])\n",
    "print(f\"scp {dir_target} bsc054620@glogin1.bsc.es:/gpfs/projects/bsc54/Capri/\")\n",
    "print(\"MN5GPU\")\n",
    "print(f\"bash capri/{target}/Predictors/AF_MODELS/Correr_Alphafold2.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# squeue ->  to see if the job is running in the server\n",
    "# scancel JOBID -> to cancel the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Relaxation (MN5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Running relaxation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following printed command with subprocess or in a terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 4px solid #1E90FF; background-color: #6FA8DC; color: #FFFFFF; padding: 10px;\">\n",
    "    <strong style=\"color: #1E90FF;\">NOTE: </strong>\n",
    "    <span style=\"color: #000000;\"> You can open the integrated terminal in VS Code by pressing `Ctrl+`` (the backtick key, which is located below the escape key on most keyboards).\n",
    "    </span>\n",
    "</div>\n",
    "<div style=\"border-left: 4px solid #1E90FF; background-color: #6FA8DC; color: #FFFFFF; padding: 10px;\">\n",
    "    <span style=\"color: #000000;\">  Open a terminal and introduce the following commands</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MN5\n",
      " cd capri/T902/Predictors/AF_MODELS/\n",
      " bash script_relax_mn5.sh \n",
      " cd COMPLEX\n",
      " sbatch T902.colabfold.relax.cmd\n"
     ]
    }
   ],
   "source": [
    "comando=f\"MN5\\n cd capri/{target}/Predictors/AF_MODELS/\\n bash script_relax_mn5.sh \\n cd COMPLEX\\n sbatch {target}.colabfold.relax.cmd\"\n",
    "print(comando)\n",
    "#subprocess.run(['bash',comando])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Checking the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following printed command with subprocess or in a terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MN5\n",
      " cd capri/T902/Predictors/AF_MODELS/COMPLEX\n",
      " cat check_min.sh |bash|wc -l vi T902.colabfold.relax.cmd\n",
      "#Si sale mal poner en el cmd:\n",
      " #T902.colabfold.relax.greasy.rst\n"
     ]
    }
   ],
   "source": [
    "print(f\"MN5\\n cd capri/{target}/Predictors/AF_MODELS/COMPLEX\\n cat check_min.sh |bash|wc -l vi {target}.colabfold.relax.cmd\")\n",
    "print(\"#Si sale mal poner en el cmd:\\n\",f\"#{target}.colabfold.relax.greasy.rst\")\n",
    "#cat check_min.sh |bash|wc -l # 315 si todo esta bien\n",
    "\n",
    "# en greasybin al final poner TXXX.colabfold.relax.greasy.rst donde TXXX es el nombre del target\n",
    "# salir guardando del vi ->  :wq \n",
    "# salir sin guardar  del vi ->  :q!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. AF3 models processing (LOCAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation of Alphafold3 Models\n",
    "1. Decompression\n",
    "\n",
    "2. Conversion to PDB\n",
    "\n",
    "3. Extraction of data from the JSON: iptm and ptm to save the model confidence in an artificial log.txt, similar to the one from Alphafold Multimer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Decompression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 4px solid; background-color:#FF6347; color: #FFFFFF; padding: 10px;\">\n",
    "    <strong style=\"color: #FF6347;\">Nota:</strong>\n",
    "    <span style=\"color: #000000;\">WARNING: rebember to download the AF3 models and have them in the dir_complex</span>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncompress the AlphaFold3 Job.\n",
    "def descomprimir_archivo(zip_path, directorio_destino):\n",
    "\n",
    "    # Ensure that the destination directory exists; if not, create it\n",
    "    if not os.path.exists(directorio_destino):\n",
    "        os.makedirs(directorio_destino)\n",
    "\n",
    "    # Open the ZIP file in read mode\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        # Extract all files into the specified directory\n",
    "        zip_ref.extractall(directorio_destino)\n",
    "\n",
    "patron = r'(.*(\\d+)\\.zip$)'\n",
    "patron_CIF = r'(.*(\\d+)\\.cif$)'\n",
    "\n",
    "zipfiles = [os.path.abspath(os.path.join(dir_complex, archivo)) for archivo in os.listdir(dir_complex) if re.match(patron, archivo)]\n",
    "print(zipfiles)\n",
    "for zipfille in zipfiles:\n",
    "    print(zipfille)\n",
    "    descomprimir_archivo(zipfille, zipfille.rstrip('.zip'))\n",
    "\n",
    "CIF_files = [os.path.abspath(os.path.join(dir_complex, archivo)) for archivo in os.listdir(zipfille.rstrip('.zip')) if re.match(patron_CIF, archivo)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Conversion to PDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert CIF files to PDB files of the AplhaFold3 Job.\n",
    "def convert_cif_to_pdb(cif_file, pdb_file):\n",
    "    \"\"\"\n",
    "    Convert a CIF file to a PDB file using Biopython.\n",
    "\n",
    "    Parameters:\n",
    "    cif_file (str): Path to the input CIF file.\n",
    "    pdb_file (str): Path to the output PDB file.\n",
    "    \"\"\"\n",
    "    parser = MMCIFParser()\n",
    "    structure = parser.get_structure('ID', cif_file)\n",
    "    io = PDBIO()\n",
    "    io.set_structure(structure)\n",
    "    io.save(pdb_file)\n",
    "\n",
    "patron_CIF = r'(.*(\\d+)\\.cif$)'\n",
    "for zipfille in zipfiles:\n",
    "    CIF_files = [os.path.join(zipfille.rstrip('.zip'),archivo) for archivo in os.listdir(zipfille.rstrip('.zip')) if re.match(patron_CIF, archivo)]\n",
    "    #print(CIF_files)\n",
    "    for CIF_file in CIF_files:\n",
    "        #print(CIF_file)\n",
    "        convert_cif_to_pdb(CIF_file, CIF_file.replace('.cif','.pdb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 JSON data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the Json\n",
    "import os\n",
    "import json\n",
    "\n",
    "def leer_json_extract_vars(directorio, claves):\n",
    "    \"\"\"\n",
    "    Lee archivos JSON en un directorio específico y extrae las variables especificadas.\n",
    "    \n",
    "    Parámetros:\n",
    "    directorio (str): Ruta al directorio que contiene los archivos JSON.\n",
    "    claves (list): Lista de claves a extraer de los archivos JSON.\n",
    "    \n",
    "    Retorna:\n",
    "    dict: Diccionario con nombres de archivo y sus variables extraídas.\n",
    "    \"\"\"\n",
    "    resultados = {}  # Diccionario para almacenar los resultados\n",
    "\n",
    "    # Recorrer todos los archivos en el directorio\n",
    "    pattern_json = re.compile(r\"summary_confidences_\\w\\.json$\")\n",
    "    for archivo in os.listdir(directorio):\n",
    "        if pattern_json.search(archivo):  # Asegurarse de que es un archivo JSON\n",
    "            ruta_completa = os.path.join(directorio, archivo)\n",
    "            with open(ruta_completa, 'r') as f:\n",
    "                data = json.load(f)  # Cargar el contenido JSON\n",
    "                # Extraer las variables especificadas\n",
    "                valores_extraidos = {clave: data.get(clave, None) for clave in claves}\n",
    "                \n",
    "                # Almacenar los resultados\n",
    "                resultados[archivo] = valores_extraidos\n",
    "\n",
    "    return resultados\n",
    "\n",
    "# Usar la función\n",
    "claves_a_extraer = ['ptm', 'iptm']  # Añadir aquí cualquier clave que necesites\n",
    "for zipfille in zipfiles:\n",
    "    log_folder = zipfille.rstrip('.zip')\n",
    "    resultados = leer_json_extract_vars(zipfille.rstrip('.zip'), claves_a_extraer)\n",
    "    with open(os.path.join(log_folder,'log.txt'), 'w') as file:\n",
    "        for archivo, vars in resultados.items():\n",
    "            # Formatear nombre del archivo y eliminar partes no deseadas\n",
    "            nombre_archivo_formateado = archivo.replace('summary_confidences', 'model').rstrip('.json')\n",
    "            # Crear una cadena de texto con los pares clave=valor\n",
    "            vars_text = ' '.join([f\"{key.replace('tm','TM')}={value}\" for key, value in vars.items()])\n",
    "            file.write(f\"{nombre_archivo_formateado} {vars_text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Upload to MN5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following printed command with subprocess or in a terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fold_t902_3', 'fold_t902_2', 'fold_t902_1']\n",
      "scp -r fold_t902_3 fold_t902_2 fold_t902_1 bsc054620@glogin1.bsc.es:/gpfs/projects/bsc54/Capri/T902/Predictors/AF_MODELS/COMPLEX/\n"
     ]
    }
   ],
   "source": [
    "patron = r'(fold)'\n",
    "dirs_AF3= [fold for fold in os.listdir(dir_complex) if re.match(patron, fold)]\n",
    "\n",
    "dirs_AF3= \" \".join(dirs_AF3)\n",
    "comando=f\"scp -r {dirs_AF3} bsc054620@glogin1.bsc.es:/gpfs/projects/bsc54/Capri/{target}/Predictors/AF_MODELS/COMPLEX/\"\n",
    "print(comando)\n",
    "#subprocess.run(['bash',comando])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. pyDock Bind Energy (MN5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Ligand and receptor asignation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ini file is created to indicate pyDock which chains are the receptors and which are the ligands, stored in CHAINS_LIG_VALUES \n",
    "The firsts letters separated by a coma is the receptor chains. The receptors are separated from the ligand with a space. The ligands are also separated separated by a coma. Example:\n",
    "\n",
    "receptor: B,C,D\n",
    "\n",
    "ligand: A\n",
    "\n",
    "result= \"B,C,D A\"\n",
    "\n",
    "If there are more combinations add an space and repeat the process adding the new combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multip=True\n",
    "if multip:\n",
    "    script_content=\"\"\"#!/bin/bash\n",
    "#rm Greasy_BindE_mul_ligs.txt;\n",
    "CHAINS_LIG_VALUES=(\n",
    "    \"B,C,D A\"\n",
    "    \"A,C,D B\"\n",
    "    \"A,B,D C\"\n",
    "    \"A,B,C D\"\n",
    "    \"A E,G\"\n",
    "    \"B I,K\"\n",
    "    \"C F,H\"\n",
    "    \"D J,L\"\n",
    ")\n",
    "\n",
    "for h in $(ls -d  T*cola*/ fold*/); do\n",
    "    echo $h;\n",
    "    cd $h;\n",
    "    for j in *.pdb; do\n",
    "        echo $j\n",
    "        for value in \"${CHAINS_LIG_VALUES[@]}\"; do\n",
    "            CHAINS_LIG=\"$value\"\n",
    "            LIG=$(echo $CHAINS_LIG | cut -d\" \" -f 2)\n",
    "            REC=$(echo $CHAINS_LIG | cut -d\" \" -f 1)\n",
    "            CH=${LIG/,/}\n",
    "            echo -e \"[receptor]\\npdb         = $j\\nmol         = $REC\\nnewmol      = $REC\" > ${j/.pdb/_LIG_${CH}.ini};\n",
    "            echo -e \"[ligand]\\npdb         = $j\\nmol         = $LIG\\nnewmol      = $LIG\" >> ${j/.pdb/_LIG_${CH}.ini};\n",
    "            echo \"cd ${h}; timeout 5m pydock4 ${j/.pdb}_LIG_${CH} bindEy; cd -\" >> ../Greasy_BindE_mul_ligs.txt;\n",
    "        done\n",
    "    done\n",
    "    cd -;\n",
    "done\n",
    "        \"\"\"\n",
    "\n",
    "    comando=f\"MN5\\n cd /home/bsc/bsc054620/capri/{target}/Predictors/AF_MODELS/COMPLEX\\n bash {script_content}\"\n",
    "    subprocess.run(['bash',f\"{comando}\"])\n",
    "else:\n",
    "    comando=f\"MN5\\n cd /home/bsc/bsc054620/capri/{target}/Predictors/AF_MODELS/COMPLEX\\n bash ./ini_creator_bindE.sh\"\n",
    "    subprocess.run(['bash',f\"{comando}\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Bind Energy calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following printed command with subprocess or in a terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MN5\n",
      " cd /home/bsc/bsc054620/capri/T902/Predictors/AF_MODELS/COMPLEX\n",
      " bash ini_creator_bindE_mutip_lig.sh\n",
      " sed -i 's/pydock4/pyDock4/g' Greasy_BindE_mul_ligs.txt\n",
      " python gen_CMD_updated_mn5.py\n",
      " sbatch Greasy_BindE_mul_ligs.cmd\n"
     ]
    }
   ],
   "source": [
    "# Energias # MN5 para acceder al modo CPU de MN5\n",
    "comando= f\"MN5\\n cd /home/bsc/bsc054620/capri/{target}/Predictors/AF_MODELS/COMPLEX\\n bash ini_creator_bindE_mutip_lig.sh\\n sed -i 's/pydock4/pyDock4/g' Greasy_BindE_mul_ligs.txt\\n python gen_CMD_updated_mn5.py\\n sbatch Greasy_BindE_mul_ligs.cmd\"\n",
    "print(comando)\n",
    "#subprocess.run(['bash',comando])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 State of archives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following printed command with subprocess or in a terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver el estado de los archivos\n",
    "\n",
    "#  cat Greasy_BindE_mul_ligs.err # como va el job\n",
    "#  find -name '*.ene'| wc -l para ver cuantos ene hay en total\n",
    "#  find -name '*.ini'| wc -l para ver cuantos ini hay en total\n",
    "\n",
    "#  If there is any error execute the rst\n",
    "\n",
    "# sumar energias de interfases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Energy summation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following printed command with subprocess or in a terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comando=f\"MN5\\n cd /home/bsc/bsc054620/capri/{target}/Predictors/AF_MODELS/COMPLEX\\n bash sum_ene_multy_bindEy_new.sh\"\n",
    "print(comando)\n",
    "#subprocess.run(['bash',comando])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Downloading MN5 files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following printed command with subprocess or in a terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comando=f\"\"\"\n",
    "cd {dir_complex}\n",
    "for i in T*.colabfold.v? fold_t* ; do echo \"scp -r bsc054620@glogin1.bsc.es:/gpfs/projects/bsc54/Capri/${target}/Predictors/AF_MODELS/COMPLEX/${{i}}/*.{{ene,pdb,txt}}  ${{i}}/ \";done|bash\n",
    "\"\"\"\n",
    "print(comando)\n",
    "#subprocess.run(['bash',comando])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
